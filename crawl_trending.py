import pandas as pd
from googleapiclient.discovery import build
from datetime import datetime
import os

API_KEY = os.getenv(API_KEY)
youtube = build("youtube", "v3", developerKey=API_KEY)

# Láº¥y danh sÃ¡ch categoryId -> categoryName
def get_video_categories(region="VN"):
    request = youtube.videoCategories().list(part="snippet", regionCode=region)
    response = request.execute()
    return {item["id"]: item["snippet"]["title"] for item in response["items"]}

# Láº¥y danh sÃ¡ch video trending
def get_trending_videos(total_results=100, region="VN"):
    categories = get_video_categories(region)
    videos, fetched = [], 0
    max_per_request = 50  # API limit
    today = datetime.now().strftime("%Y-%m-%d")      # ğŸ†• NgÃ y crawl
    now_time = datetime.now().strftime("%H:%M:%S")   # ğŸ†• Giá» crawl

    while fetched < total_results:
        to_fetch = min(max_per_request, total_results - fetched)
        request = youtube.videos().list(
            part="snippet,statistics",
            chart="mostPopular",
            regionCode=region,
            maxResults=to_fetch
        )
        response = request.execute()

        for idx, item in enumerate(response.get("items", []), start=fetched+1):
            cat_id = item["snippet"].get("categoryId", "N/A")
            stats = item.get("statistics", {})
            publish_date = item["snippet"]["publishedAt"][:10]  # YYYY-MM-DD

            videos.append({
                "videoId": item["id"],
                "title": item["snippet"]["title"],
                "channelTitle": item["snippet"]["channelTitle"],
                "category": categories.get(cat_id, "Unknown"),
                "publishDate": publish_date,       # ngÃ y Ä‘Äƒng video
                "collectDate": today,              # ngÃ y thu tháº­p
                "collectTime": now_time,           # ğŸ†• giá» thu tháº­p
                "region": region,                  # khu vá»±c
                "rank": idx,                       # táº¡m rank theo lÆ°á»£t láº¥y
                "viewCount": stats.get("viewCount", 0),
                "likeCount": stats.get("likeCount", 0),
                "commentCount": stats.get("commentCount", 0),
            })
        fetched += len(response.get("items", []))
        if len(response.get("items", [])) < to_fetch:
            break
    return videos

# ğŸ“Œ Crawl cho nhiá»u region
regions = ["VN", "US", "KR"]
all_videos = []

for region in regions:
    print(f"ğŸ“¥ Äang crawl {region} ...")
    videos = get_trending_videos(50, region)
    all_videos.extend(videos)

df_new = pd.DataFrame(all_videos)

# ğŸ“Œ File CSV chung
file_name = "youtube_trending.csv"

if os.path.exists(file_name):
    df_old = pd.read_csv(file_name, encoding="utf-8-sig")
    # Gá»™p dá»¯ liá»‡u má»›i + cÅ© (KHÃ”NG bá» trÃ¹ng)
    df_final = pd.concat([df_old, df_new], ignore_index=True)
else:
    df_final = df_new

# Reset rank cho tá»«ng collectDate + region
df_final["rank"] = (
    df_final.groupby(["collectDate", "region"])
    .cumcount() + 1
)

# Ghi file
columns_order = [
    "videoId","title","channelTitle","category",
    "publishDate","collectDate","collectTime",
    "region","rank","viewCount","likeCount","commentCount"
]
df_final.to_csv(file_name, index=False, encoding="utf-8-sig", columns=columns_order)

print(f"âœ… ÄÃ£ thÃªm {len(df_new)} video trending ({', '.join(regions)}), "
      f"file hiá»‡n cÃ³ {len(df_final)} báº£n ghi.")
